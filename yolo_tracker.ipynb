{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f8bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fbd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting index to either 1 (Mac camera), or 0 (iPhone camera)\n",
    "cam_idx = 0\n",
    "\n",
    "# Using YOLO 11n for person detection\n",
    "model = YOLO(\"yolo11n.pt\")      \n",
    "\n",
    "# Storing appearance features (color histograms) and count of unique people\n",
    "known_appearances = []\n",
    "unique_person_count = 0\n",
    "\n",
    "# Assigning IDs to unique individuals\n",
    "person_names = []           # Storing the ID for each known appearance\n",
    "used_names = set()     # Tracking used names to avoid duplicates\n",
    "\n",
    "# Setting the similarity threshold \n",
    "# Lower = less duplicates. Higher = less failing to recognize someone is new.\n",
    "SIMILARITY_THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd36820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to grab the color histogram of clothes for people on camera\n",
    "def extract_appearance_features(person_img):\n",
    "\n",
    "    # Converting color space to HSV for better comparison capabilities\n",
    "    hsv = cv2.cvtColor(person_img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Computing individual histograms for H, S, and V\n",
    "    # Indexes are: Channel, Mask (none here), number of bins, and Value Range in Open CV.\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [50], [0, 180])\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [60], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [60], [0, 256])\n",
    "    \n",
    "    # Now we normalize the histograms\n",
    "    cv2.normalize(hist_h, hist_h)\n",
    "    cv2.normalize(hist_s, hist_s)\n",
    "    cv2.normalize(hist_v, hist_v)\n",
    "    \n",
    "    # Then we concatenate all the histograms into one feature vector\n",
    "    features = np.concatenate([hist_h.flatten(), hist_s.flatten(), hist_v.flatten()])\n",
    "\n",
    "    # And what the function returns is that feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9e8786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to compare histograms so that we don't count duplicates\n",
    "def compare_appearances(features1, features2):\n",
    "\n",
    "    # Measuring similarity of a feature vector with another\n",
    "    similarity = np.dot(features1, features2) / (np.linalg.norm(features1) * np.linalg.norm(features2))\n",
    "\n",
    "    # And we return how similar they are\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72d4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this block let's create what we need to assign funny identifiers to anyone captured\n",
    "# Note: at 30 adjectives and 30 animal names, our nax count is 900 individual identifiers.\n",
    "# Add more adjectives and names if need to go higher\n",
    "# Or even better, add a third list type (color, etc) to multiply the number of options.\n",
    "\n",
    "# List of adjectives \n",
    "adjectives = [\n",
    "    \"Fuzzy\", \"Pink\", \"Hyperactive\", \"Sleepy\", \"Grumpy\", \"Happy\", \"Bouncy\", \n",
    "    \"Sneaky\", \"Wise\", \"Mighty\", \"Tiny\", \"Giant\", \"Swift\", \"Lazy\", \"Brave\",\n",
    "    \"Silly\", \"Clever\", \"Dancing\", \"Flying\", \"Swimming\", \"Quiet\", \"Loud\",\n",
    "    \"Sparkly\", \"Shiny\", \"Fluffy\", \"Smooth\", \"Spiky\", \"Gentle\", \"Wild\", \"Calm\"\n",
    "]\n",
    "\n",
    "# List of animal names\n",
    "animals = [\n",
    "    \"Panda\", \"Monkey\", \"Turtle\", \"Eagle\", \"Dolphin\", \"Lion\", \"Tiger\", \"Bear\",\n",
    "    \"Fox\", \"Wolf\", \"Elephant\", \"Giraffe\", \"Penguin\", \"Koala\", \"Kangaroo\",\n",
    "    \"Octopus\", \"Owl\", \"Rabbit\", \"Squirrel\", \"Hedgehog\", \"Raccoon\", \"Otter\",\n",
    "    \"Seal\", \"Kraken\", \"Shark\", \"Parrot\", \"Flamingo\", \"Zebra\", \"Axolotl\", \"Rhino\"\n",
    "]\n",
    "\n",
    "# And here's the function to generate adjective / name identifiers\n",
    "def generate_unique_name(used_names):\n",
    "    while True:\n",
    "        adjective = random.choice(adjectives)\n",
    "        animal = random.choice(animals)\n",
    "        name = f\"{adjective} {animal}\"\n",
    "        if name not in used_names:\n",
    "            used_names.add(name)\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933478d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing appearance features and assigning names\n",
    "known_appearances = []      # Storing the feature vectors for each person\n",
    "person_names = []           # Storing the name for each known person\n",
    "person_has_left = []        # Tracking if person has ever left the frame\n",
    "last_frame_ids = set() # Tracking who was in the previous frame\n",
    "used_names = set()     # Tracking used names to avoid duplicates\n",
    "unique_person_count = 0     # Initializing a counter of unique people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4553c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New person detected: Bouncy Seal | Total unique: 1\n",
      "New person detected: Sneaky Owl | Total unique: 2\n",
      "Camera released, OpenCV windows closed.\n",
      "Total unique people detected: 2\n"
     ]
    }
   ],
   "source": [
    "# Camera, Open Sesame!\n",
    "cap = cv2.VideoCapture(cam_idx, cv2.CAP_AVFOUNDATION)\n",
    "\n",
    "# Yay error handling, just in case\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not open camera {cam_idx}\")\n",
    "\n",
    "# Creating a capture loop to grab people\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "\n",
    "    # Yay error handling\n",
    "    if not ok:\n",
    "        print(\"Failed to read the frame, try again!\")\n",
    "        break\n",
    "\n",
    "    # Detecting people with YOLO\n",
    "    results = model(\n",
    "        frame,\n",
    "        imgsz=640,\n",
    "        classes=[0],\n",
    "        verbose=False,\n",
    "        conf=0.5\n",
    "    )[0]\n",
    "    \n",
    "    # Creating variable to start the counting \n",
    "    current_frame_count = 0\n",
    "    current_frame_ids = set()  # Track who's in this frame\n",
    "    \n",
    "    # When a person is detected, let's grab them\n",
    "    if len(results.boxes) > 0:\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            person_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            # Let's not count any people who are lilliputians (or too far away)\n",
    "            if person_img.shape[0] < 50 or person_img.shape[1] < 30:\n",
    "                continue\n",
    "            \n",
    "            # Now we grab our captured person and we extract an embedding for their appearance.\n",
    "            features = extract_appearance_features(person_img)\n",
    "            is_new_person = True   # Setting to True for now, we'll flip it to False if a match is found\n",
    "            person_name = None\n",
    "            person_idx = None\n",
    "            \n",
    "            # Comparing to existing embeddings, and avoiding counting if there's a match\n",
    "            for idx, known_features in enumerate(known_appearances):\n",
    "                similarity = compare_appearances(features, known_features)\n",
    "                if similarity > SIMILARITY_THRESHOLD:\n",
    "                    is_new_person = False\n",
    "                    person_name = person_names[idx]  # Get the name of the matched person\n",
    "                    person_idx = idx\n",
    "                    break\n",
    "            \n",
    "            # For people that don't match existing captures, lets add them and create a new name\n",
    "            if is_new_person:\n",
    "                known_appearances.append(features)\n",
    "                person_name = generate_unique_name(used_names)\n",
    "                person_names.append(person_name)\n",
    "                person_has_left.append(False)  # First time seeing this person\n",
    "                person_idx = len(person_names) - 1\n",
    "                unique_person_count += 1\n",
    "                print(f\"New person detected: {person_name} | Total unique: {unique_person_count}\")\n",
    "            \n",
    "            current_frame_ids.add(person_idx)\n",
    "            \n",
    "            # Incrementing the frame count\n",
    "            current_frame_count += 1\n",
    "\n",
    "            # Drawing the bounding box (yellow if never left, green if has left before)\n",
    "            color = (0, 255, 255) if not person_has_left[person_idx] else (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            # Displaying the person's name above the bounding box\n",
    "            cv2.putText(frame, person_name, \n",
    "                (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "    \n",
    "    # Checking who left the frame (was in last frame but not in current frame)\n",
    "    people_who_left = last_frame_ids - current_frame_ids\n",
    "    for idx in people_who_left:\n",
    "        person_has_left[idx] = True  # Marking that they've left at least once\n",
    "    \n",
    "    # Updating last frame tracking\n",
    "    last_frame_ids = current_frame_ids.copy()\n",
    "    \n",
    "    # Showing how many people are in frame, and how many unique visitors we've seen total\n",
    "    cv2.putText(frame, f\"Current: {current_frame_count}  Total unique: {unique_person_count}\",\n",
    "                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Showing which visitors are new, and which are known\n",
    "    cv2.putText(frame, \"Yellow=First visit  Green=Return visit\", \n",
    "                (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "    # Providing a way to quit capturing visitors \n",
    "    cv2.imshow(\"People counter (press q to quit)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"People counter (press q to quit)\", frame)\n",
    "\n",
    "    # Most stable key polling on macOS:\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):  # clean comparison, no bitmask\n",
    "        print(\"Quit signal received\")\n",
    "        break\n",
    "\n",
    "# Closing the camera and the OpenCV window showing people tracked\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "time.sleep(0.2)  # allow OS event loop flush\n",
    "cv2.destroyAllWindows()  # second call to enforce close\n",
    "print(\"Camera released, OpenCV windows closed.\")\n",
    "\n",
    "# Printing out total number of individual people detected\n",
    "print(f\"Total unique people detected: {unique_person_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
